{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **ChatGPT OUTPUT**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Q1\n",
        "\n",
        "\n",
        "Assess which customers are likely to churn (when a customer ceases to be a customer) so that the bank can take proactive measures to retain them. Develop interactive dashboards to identify customers at risk of churning and provide actionable insights to reduce churn rates.\n",
        "\n",
        "how we can do?\n",
        "\n",
        "** Key columns for churn analysis:\n",
        "\n",
        "Customer profile: Age, Gender, Education, Marital Status, Income Category.\n",
        "Account details: Months on book, Card Category, Credit Limit.\n",
        "Engagement & activity: Total Relationship Count, Months Inactive in the last 12 months, Contact Count, Transaction Amount & Count, Average Utilization Ratio.\n",
        "Change indicators: Total Transaction and Amount Change from Q4 to Q1.\n",
        "Next steps:\n",
        "\n",
        "Preprocess the data: Convert categorical values, clean unnecessary columns, and create a binary churn label.\n",
        "Exploratory Data Analysis (EDA): Identify patterns in churn behavior.\n",
        "Develop a churn prediction model.\n",
        "Build interactive dashboards for insights and prevention strategies.\n",
        "\n",
        "After The dataset cleaned and preprocessed:\n",
        "\n",
        "The churn label is encoded as 1 (churned) and 0 (existing customer).\n",
        "Irrelevant columns (client ID, Naïve Bayes classifiers) are removed.\n",
        "Categorical features (gender, education, marital status, income, and card category) are converted into dummy variables.\n",
        "\n",
        "* Insights from Data Exploration:\n",
        "Churn Rate: The churn distribution plot shows a significant class imbalance, meaning fewer customers have churned compared to those retained.\n",
        "Key Correlations with Churn:\n",
        "Months Inactive (Last 12 Months) and Contacts Count (Last 12 Months) have a strong positive correlation with churn.\n",
        "Total Transactions (Count & Amount) and Total Relationship Count are negatively correlated, meaning active engagement reduces churn risk.\n",
        "Credit Utilization Ratio and Total Revolving Balance also show some correlation, suggesting financial stress may impact churn.\n",
        "\n",
        "* Next Steps:\n",
        "Feature importance analysis with a machine learning model.\n",
        "Building an interactive dashboard to track customer engagement and risk factors.\n",
        "Churn prediction model to help in proactive customer retention strategies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q2\n",
        "\n",
        "we have hypotesis \n",
        "* Women have a higher chance of leaving\n",
        "* There are specific ages group more likely to leave\n",
        "* We can forcast chance of leaving based on number of transactions\n",
        "* Customers with unknown income are more likely to leave.\n",
        "\n",
        "when we asked to ChatGPT : how we can data analyse ?\n",
        "\n",
        "1. Women have a higher chance of leaving\n",
        "Steps:\n",
        "•\tCalculate the churn rate for each gender.\n",
        "•\tUse a bar plot to compare churn rates.\n",
        "\n",
        " \n",
        "2. Specific age groups are more likely to leave\n",
        "Steps:\n",
        "•\tDivide customers into age groups (e.g., 18-30, 31-45, 46-60, etc.).\n",
        "•\tCompare churn rates across age groups.\n",
        "\n",
        "3. Forecast chance of leaving based on number of transactions\n",
        "Steps:\n",
        "•\tUse logistic regression or decision trees to predict churn based on transaction count.\n",
        "•\tVisualize the relationship between Total_Trans_Ct and churn.\n",
        "\n",
        "4. Customers with unknown income are more likely to leave\n",
        "Steps:\n",
        "•\tCompare churn rates for different income groups, especially \"Unknown\" income.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "which is the best model we can see the churns ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you want to predict customer churn, the best models are classification models. Here are the top options:\n",
        "\n",
        "1. Logistic Regression\n",
        "Simple and interpretable.\n",
        "Works well with small datasets.\n",
        "Advantage: Provides churn probability for each customer.\n",
        "2. Decision Trees\n",
        "Rule-based and easy to visualize.\n",
        "Fast on small datasets.\n",
        "Disadvantage: Can overfit easily.\n",
        "3. Random Forest\n",
        "An ensemble of multiple decision trees.\n",
        "Reduces overfitting and improves accuracy.\n",
        "Advantage: Helps identify the most important features.\n",
        "4. XGBoost (Gradient Boosting)\n",
        "One of the best-performing models for churn prediction.\n",
        "Works well with large and complex datasets.\n",
        "Advantage: Handles missing values and achieves high accuracy.\n",
        "5. Neural Networks\n",
        "Can capture complex patterns in the data.\n",
        "Suitable for large datasets with many features.\n",
        "Disadvantage: Hard to interpret and requires more data.\n",
        "Which Model Should You Choose?\n",
        "\n",
        "✅ For quick and interpretable results: Logistic Regression or Decision Trees\n",
        "\n",
        "✅ For high accuracy and balanced performance: Random Forest or XGBoost\n",
        "\n",
        "✅ For large datasets and deep learning: Neural Networks\n",
        "\n",
        "Recommendation: Start with Logistic Regression and Random Forest, then optimize with XGBoost."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Nov  7 2022, 16:45:55) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
